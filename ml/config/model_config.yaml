# Electricity Price Forecasting Model Configuration
# CNN-LSTM with Attention Mechanism

# ============================================================
# Model Architecture Configuration
# ============================================================

model:
  name: "electricity_price_forecaster"
  version: "1.0.0"

  # Input/Output Configuration
  input:
    sequence_length: 168  # 7 days of hourly data
    num_features: 15      # Number of input features

  output:
    forecast_horizon: 24  # 24-hour ahead forecast
    num_outputs: 3        # point estimate, lower bound, upper bound
    confidence_level: 0.9 # 90% confidence interval

  # CNN Configuration
  cnn:
    filters: [64, 128, 64]
    kernel_sizes: [3, 5, 3]
    pooling_size: 2
    activation: "relu"
    batch_norm: true

  # LSTM Configuration
  lstm:
    units: [128, 64]
    return_sequences: [true, false]
    dropout: 0.2
    recurrent_dropout: 0.1

  # Attention Configuration
  attention:
    enabled: true
    heads: 4
    key_dim: 32
    dropout: 0.1

  # Dense Layers Configuration
  dense:
    units: [64, 32]
    activation: "relu"
    dropout: 0.3

  # Output Layer
  output_layer:
    activation: "linear"  # Linear for regression

# ============================================================
# Training Configuration
# ============================================================

training:
  # Basic Training Parameters
  batch_size: 32
  epochs: 200
  validation_split: 0.15

  # Optimizer Configuration
  optimizer:
    name: "adam"
    learning_rate: 0.001
    beta_1: 0.9
    beta_2: 0.999
    epsilon: 1.0e-7

  # Learning Rate Schedule
  lr_schedule:
    enabled: true
    type: "reduce_on_plateau"
    factor: 0.5
    patience: 10
    min_lr: 1.0e-6

  # Loss Function
  loss:
    name: "mse"  # Mean Squared Error for training

  # Metrics to Track
  metrics:
    - "mae"
    - "mape"

  # Early Stopping
  early_stopping:
    enabled: true
    monitor: "val_loss"
    patience: 20
    restore_best_weights: true
    min_delta: 0.0001

  # Model Checkpointing
  checkpoint:
    enabled: true
    monitor: "val_mape"
    save_best_only: true
    save_weights_only: false

  # Regularization
  regularization:
    l2_weight: 0.0001
    dropout_rate: 0.3

# ============================================================
# Feature Engineering Configuration
# ============================================================

features:
  # Price Features
  price:
    - spot_price
    - day_ahead_price
    - price_lag_1h
    - price_lag_24h
    - price_lag_168h
    - price_rolling_mean_24h
    - price_rolling_std_24h

  # Time Features
  temporal:
    - hour_of_day
    - day_of_week
    - month
    - is_weekend
    - is_holiday

  # Weather Features
  weather:
    - temperature
    - wind_speed
    - solar_radiation
    - cloud_cover

  # Generation Mix Features
  generation:
    - renewable_percentage
    - fossil_percentage
    - nuclear_percentage

  # Demand Features
  demand:
    - load_forecast
    - load_rolling_mean_24h
    - load_lag_24h

  # Seasonal Decomposition
  seasonal:
    - trend_component
    - seasonal_component
    - residual_component

  # Feature Scaling
  scaling:
    method: "standard"  # standard, minmax, robust
    fit_on_train_only: true

# ============================================================
# Ensemble Configuration
# ============================================================

ensemble:
  enabled: true
  method: "weighted_average"  # weighted_average, stacking

  # XGBoost Configuration
  xgboost:
    enabled: true
    weight: 0.25
    params:
      n_estimators: 500
      max_depth: 8
      learning_rate: 0.05
      subsample: 0.8
      colsample_bytree: 0.8
      min_child_weight: 3
      reg_alpha: 0.1
      reg_lambda: 1.0
      objective: "reg:squarederror"
      tree_method: "hist"

  # LightGBM Configuration
  lightgbm:
    enabled: true
    weight: 0.25
    params:
      n_estimators: 500
      max_depth: 8
      learning_rate: 0.05
      num_leaves: 31
      subsample: 0.8
      colsample_bytree: 0.8
      min_child_samples: 20
      reg_alpha: 0.1
      reg_lambda: 1.0
      objective: "regression"
      boosting_type: "gbdt"

  # CNN-LSTM Weight
  cnn_lstm:
    weight: 0.5

# ============================================================
# Evaluation Configuration
# ============================================================

evaluation:
  # Metrics to Compute
  metrics:
    - mape
    - rmse
    - mae
    - r2
    - direction_accuracy

  # Backtesting Configuration
  backtesting:
    window_type: "expanding"  # expanding, rolling
    min_train_size: 8760      # 1 year of hourly data
    test_size: 720            # 30 days of hourly data
    step_size: 168            # Re-train weekly

  # Performance Targets
  targets:
    mape: 10.0      # Target: MAPE < 10%
    rmse: 15.0      # EUR/MWh
    direction_accuracy: 0.7  # 70% correct direction

# ============================================================
# Data Configuration
# ============================================================

data:
  # Data Sources
  sources:
    prices: "data/prices/"
    weather: "data/weather/"
    generation: "data/generation/"
    demand: "data/demand/"

  # Data Quality
  quality:
    max_missing_ratio: 0.05
    outlier_method: "iqr"
    outlier_threshold: 3.0

  # Train/Val/Test Split
  split:
    train_ratio: 0.7
    val_ratio: 0.15
    test_ratio: 0.15
    temporal_split: true  # Respect time ordering

# ============================================================
# Inference Configuration
# ============================================================

inference:
  max_latency_ms: 1000  # < 1 second requirement
  batch_inference: true
  batch_size: 100

  # Caching
  cache:
    enabled: true
    ttl_minutes: 60

# ============================================================
# Paths Configuration
# ============================================================

paths:
  models: "ml/saved_models/"
  checkpoints: "ml/checkpoints/"
  logs: "ml/logs/"
  predictions: "ml/predictions/"
  experiments: "ml/experiments/"
