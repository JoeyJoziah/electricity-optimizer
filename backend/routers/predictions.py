"""
Predictions API Router - ML Model Serving Endpoints

Provides RESTful API for electricity price predictions and optimization:
- /predict/price: 24-hour price forecast
- /predict/optimal-times: Cheapest periods for appliance scheduling
- /predict/savings: Estimated cost savings from optimization
"""

from fastapi import APIRouter, HTTPException, Depends, Query, status
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field, validator
from typing import List, Optional, Dict, Any
from datetime import datetime, timedelta
from enum import Enum
import numpy as np
import asyncio

from config.database import get_redis, get_timescale_session
from sqlalchemy.ext.asyncio import AsyncSession
import structlog

logger = structlog.get_logger(__name__)

router = APIRouter()


# ============================================================================
# REQUEST/RESPONSE MODELS
# ============================================================================

class Region(str, Enum):
    """Supported regions for price forecasting"""
    UK = "UK"
    US = "US"
    EU = "EU"
    GERMANY = "GERMANY"
    FRANCE = "FRANCE"
    SPAIN = "SPAIN"


class PriceForecastRequest(BaseModel):
    """Request for price forecast"""
    region: Region
    hours_ahead: int = Field(default=24, ge=1, le=168, description="Hours to forecast (1-168)")
    include_confidence: bool = Field(default=True, description="Include confidence intervals")


class PricePrediction(BaseModel):
    """Single price prediction"""
    timestamp: datetime
    predicted_price: float = Field(description="Predicted price in local currency per kWh")
    confidence_lower: Optional[float] = Field(None, description="Lower bound (95% confidence)")
    confidence_upper: Optional[float] = Field(None, description="Upper bound (95% confidence)")
    currency: str = Field(default="GBP")


class PriceForecastResponse(BaseModel):
    """Price forecast response"""
    region: str
    forecast_time: datetime
    model_version: str
    predictions: List[PricePrediction]
    accuracy_mape: Optional[float] = Field(None, description="Recent model accuracy (MAPE %)")


class OptimalTimeSlot(BaseModel):
    """Optimal time slot for appliance usage"""
    start_time: datetime
    end_time: datetime
    duration_hours: float
    average_price: float
    total_cost: float
    rank: int = Field(description="1 = cheapest, 2 = second cheapest, etc.")


class OptimalTimesRequest(BaseModel):
    """Request for optimal time slots"""
    region: Region
    duration_hours: float = Field(ge=0.25, le=24, description="Required duration (0.25-24 hours)")
    earliest_start: Optional[datetime] = Field(None, description="Earliest acceptable start time")
    latest_end: Optional[datetime] = Field(None, description="Latest acceptable end time")
    num_slots: int = Field(default=3, ge=1, le=10, description="Number of optimal slots to return")


class OptimalTimesResponse(BaseModel):
    """Optimal time slots response"""
    region: str
    requested_duration_hours: float
    optimal_slots: List[OptimalTimeSlot]
    potential_savings_percent: float


class ApplianceSchedule(BaseModel):
    """Appliance for optimization"""
    name: str
    power_kw: float = Field(gt=0, description="Power consumption in kW")
    duration_hours: float = Field(gt=0, le=24, description="Required runtime (hours)")
    earliest_start: datetime
    latest_end: datetime
    continuous: bool = Field(default=True, description="Must run continuously")


class SavingsEstimateRequest(BaseModel):
    """Request for savings estimate"""
    region: Region
    appliances: List[ApplianceSchedule]


class SavingsEstimateResponse(BaseModel):
    """Savings estimate response"""
    region: str
    unoptimized_cost: float
    optimized_cost: float
    savings_amount: float
    savings_percent: float
    currency: str
    optimized_schedule: Dict[str, Dict[str, Any]]


# ============================================================================
# HELPER FUNCTIONS
# ============================================================================

async def get_latest_model_version(redis_client) -> str:
    """Get latest deployed model version from cache"""
    if not redis_client:
        return "v1.0.0"
    try:
        version = await redis_client.get("model:latest_version")
        return version if version else "v1.0.0"
    except Exception:
        return "v1.0.0"


async def get_model_accuracy(redis_client) -> Optional[float]:
    """Get recent model accuracy (MAPE) from cache"""
    if not redis_client:
        return None
    try:
        mape = await redis_client.get("model:recent_mape")
        return float(mape) if mape else None
    except Exception:
        return None


async def load_forecast_from_cache(
    redis_client,
    region: str,
    hours_ahead: int
) -> Optional[List[Dict]]:
    """Load cached forecast if available"""
    if not redis_client:
        return None
    try:
        cache_key = f"forecast:{region}:{hours_ahead}"
        cached = await redis_client.get(cache_key)
        if cached:
            import json
            return json.loads(cached)
    except Exception:
        pass
    return None


async def store_forecast_in_cache(
    redis_client,
    region: str,
    hours_ahead: int,
    forecast: List[Dict],
    ttl_seconds: int = 3600
):
    """Store forecast in cache"""
    if not redis_client:
        return
    try:
        import json
        cache_key = f"forecast:{region}:{hours_ahead}"
        await redis_client.setex(
            cache_key,
            ttl_seconds,
            json.dumps(forecast, default=str)
        )
    except Exception:
        pass


async def generate_price_forecast(
    region: str,
    hours_ahead: int,
    session: AsyncSession
) -> List[PricePrediction]:
    """
    Generate price forecast using ML model

    In production, this would:
    1. Load the trained model from disk/S3
    2. Fetch recent historical data
    3. Run feature engineering
    4. Generate predictions
    5. Calculate confidence intervals

    For now, returns simulated forecast
    """
    # TODO: Implement actual model inference
    # from ml.models.price_forecaster import load_model, predict
    # model = load_model('latest')
    # predictions = model.predict(features)

    # Simulated forecast for demonstration
    base_time = datetime.utcnow().replace(minute=0, second=0, microsecond=0)
    predictions = []

    for i in range(hours_ahead):
        timestamp = base_time + timedelta(hours=i+1)

        # Simulate price with daily pattern
        hour = timestamp.hour
        base_price = 0.20 + 0.05 * np.sin((hour - 6) * np.pi / 12)

        # Add some randomness
        noise = np.random.normal(0, 0.01)
        predicted_price = max(0.01, base_price + noise)

        # Confidence intervals (Â± 15%)
        confidence_lower = predicted_price * 0.85
        confidence_upper = predicted_price * 1.15

        predictions.append(PricePrediction(
            timestamp=timestamp,
            predicted_price=round(predicted_price, 4),
            confidence_lower=round(confidence_lower, 4),
            confidence_upper=round(confidence_upper, 4),
            currency="GBP" if region in ["UK"] else "USD"
        ))

    return predictions


# ============================================================================
# API ENDPOINTS
# ============================================================================

@router.post("/predict/price", response_model=PriceForecastResponse, tags=["Predictions"])
async def predict_prices(
    request: PriceForecastRequest,
    redis_client = Depends(get_redis),
    session: AsyncSession = Depends(get_timescale_session)
):
    """
    Generate electricity price forecast

    Returns predicted prices for the next 1-168 hours with confidence intervals.

    **Performance**: Cached for 1 hour, <100ms response time

    **Example**:
    ```json
    {
      "region": "UK",
      "hours_ahead": 24,
      "include_confidence": true
    }
    ```
    """
    logger.info("price_forecast_request", region=request.region, hours=request.hours_ahead)

    try:
        # Check cache first (skip if redis not available)
        if redis_client:
            cached_forecast = await load_forecast_from_cache(
                redis_client,
                request.region.value,
                request.hours_ahead
            )

            if cached_forecast:
                logger.info("forecast_cache_hit")
                return JSONResponse(content=cached_forecast)

        # Generate forecast
        predictions = await generate_price_forecast(
            request.region.value,
            request.hours_ahead,
            session
        )

        # Get model metadata (skip if redis not available)
        model_version = "v1.0.0"
        accuracy_mape = None
        if redis_client:
            model_version = await get_latest_model_version(redis_client)
            accuracy_mape = await get_model_accuracy(redis_client)

        response = PriceForecastResponse(
            region=request.region.value,
            forecast_time=datetime.utcnow(),
            model_version=model_version,
            predictions=predictions,
            accuracy_mape=accuracy_mape
        )

        # Cache the forecast (skip if redis not available)
        if redis_client:
            await store_forecast_in_cache(
                redis_client,
                request.region.value,
                request.hours_ahead,
                response.dict(),
                ttl_seconds=3600  # 1 hour
            )

        logger.info("forecast_generated", num_predictions=len(predictions))
        return response

    except Exception as e:
        logger.error("forecast_generation_failed", error=str(e))
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to generate forecast: {str(e)}"
        )


@router.post("/predict/optimal-times", response_model=OptimalTimesResponse, tags=["Predictions"])
async def find_optimal_times(
    request: OptimalTimesRequest,
    redis_client = Depends(get_redis),
    session: AsyncSession = Depends(get_timescale_session)
):
    """
    Find optimal time slots for running appliances

    Returns the cheapest time periods to run an appliance based on forecasted prices.

    **Use case**: "When should I run my dishwasher to minimize cost?"

    **Example**:
    ```json
    {
      "region": "UK",
      "duration_hours": 2.0,
      "earliest_start": "2026-02-06T18:00:00Z",
      "latest_end": "2026-02-07T08:00:00Z",
      "num_slots": 3
    }
    ```
    """
    logger.info("optimal_times_request", region=request.region, duration=request.duration_hours)

    try:
        # Get 24-hour forecast
        predictions = await generate_price_forecast(request.region.value, 24, session)

        # Filter by time window if specified
        if request.earliest_start or request.latest_end:
            earliest = request.earliest_start or datetime.utcnow()
            latest = request.latest_end or (datetime.utcnow() + timedelta(days=1))

            predictions = [
                p for p in predictions
                if earliest <= p.timestamp <= latest
            ]

        # Find optimal slots using sliding window
        slots = []
        duration_slots = int(request.duration_hours * 4)  # 15-min intervals

        for i in range(len(predictions) - duration_slots + 1):
            window = predictions[i:i + duration_slots]

            avg_price = np.mean([p.predicted_price for p in window])
            total_cost = sum(p.predicted_price for p in window) * request.duration_hours / len(window)

            slots.append(OptimalTimeSlot(
                start_time=window[0].timestamp,
                end_time=window[-1].timestamp,
                duration_hours=request.duration_hours,
                average_price=round(avg_price, 4),
                total_cost=round(total_cost, 4),
                rank=0  # Will be set after sorting
            ))

        # Sort by average price and take top N
        slots.sort(key=lambda x: x.average_price)
        top_slots = slots[:request.num_slots]

        # Assign ranks
        for idx, slot in enumerate(top_slots):
            slot.rank = idx + 1

        # Calculate potential savings
        worst_price = max(s.average_price for s in slots)
        best_price = top_slots[0].average_price
        savings_percent = ((worst_price - best_price) / worst_price * 100) if worst_price > 0 else 0

        return OptimalTimesResponse(
            region=request.region.value,
            requested_duration_hours=request.duration_hours,
            optimal_slots=top_slots,
            potential_savings_percent=round(savings_percent, 2)
        )

    except Exception as e:
        logger.error("optimal_times_failed", error=str(e))
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to find optimal times: {str(e)}"
        )


@router.post("/predict/savings", response_model=SavingsEstimateResponse, tags=["Predictions"])
async def estimate_savings(
    request: SavingsEstimateRequest,
    redis_client = Depends(get_redis),
    session: AsyncSession = Depends(get_timescale_session)
):
    """
    Estimate cost savings from appliance optimization

    Compares immediate execution vs optimal scheduling for multiple appliances.

    **Use case**: "How much can I save by scheduling my appliances optimally?"

    **Example**:
    ```json
    {
      "region": "UK",
      "appliances": [
        {
          "name": "Dishwasher",
          "power_kw": 1.5,
          "duration_hours": 2.0,
          "earliest_start": "2026-02-06T18:00:00Z",
          "latest_end": "2026-02-07T08:00:00Z",
          "continuous": true
        }
      ]
    }
    ```
    """
    logger.info("savings_estimate_request", region=request.region, num_appliances=len(request.appliances))

    try:
        # Get 24-hour forecast
        predictions = await generate_price_forecast(request.region.value, 24, session)

        # Calculate unoptimized cost (run immediately)
        current_price = predictions[0].predicted_price
        unoptimized_cost = sum(
            a.power_kw * a.duration_hours * current_price
            for a in request.appliances
        )

        # Calculate optimized cost and schedule
        optimized_cost = 0
        optimized_schedule = {}

        for appliance in request.appliances:
            # Find optimal time for this appliance
            optimal_result = await find_optimal_times(
                OptimalTimesRequest(
                    region=request.region,
                    duration_hours=appliance.duration_hours,
                    earliest_start=appliance.earliest_start,
                    latest_end=appliance.latest_end,
                    num_slots=1
                ),
                redis_client,
                session
            )

            best_slot = optimal_result.optimal_slots[0]
            appliance_cost = appliance.power_kw * appliance.duration_hours * best_slot.average_price

            optimized_cost += appliance_cost
            optimized_schedule[appliance.name] = {
                "start_time": best_slot.start_time.isoformat(),
                "end_time": best_slot.end_time.isoformat(),
                "cost": round(appliance_cost, 4),
                "average_price": best_slot.average_price
            }

        savings_amount = unoptimized_cost - optimized_cost
        savings_percent = (savings_amount / unoptimized_cost * 100) if unoptimized_cost > 0 else 0

        return SavingsEstimateResponse(
            region=request.region.value,
            unoptimized_cost=round(unoptimized_cost, 4),
            optimized_cost=round(optimized_cost, 4),
            savings_amount=round(savings_amount, 4),
            savings_percent=round(savings_percent, 2),
            currency="GBP" if request.region in [Region.UK] else "USD",
            optimized_schedule=optimized_schedule
        )

    except Exception as e:
        logger.error("savings_estimate_failed", error=str(e))
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to estimate savings: {str(e)}"
        )


@router.get("/predict/model-info", tags=["Predictions"])
async def get_model_info(redis_client = Depends(get_redis)):
    """
    Get information about the deployed forecasting model

    Returns model version, accuracy metrics, and metadata.
    """
    model_version = "v1.0.0"
    accuracy_mape = None
    if redis_client:
        model_version = await get_latest_model_version(redis_client)
        accuracy_mape = await get_model_accuracy(redis_client)

    return {
        "model_version": model_version,
        "accuracy_mape": accuracy_mape,
        "model_type": "CNN-LSTM Ensemble",
        "forecast_horizon_hours": 24,
        "update_frequency": "hourly",
        "training_frequency": "weekly",
        "last_updated": "2026-02-06T10:00:00Z"  # TODO: Get from DB
    }
